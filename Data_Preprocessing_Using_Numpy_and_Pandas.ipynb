{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbDKqfnnObrwPMzUd4AF1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paranthaman76/ai-job-dataset/blob/main/Data_Preprocessing_Using_Numpy_and_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzPw2vReCyYg",
        "outputId": "bad25cf0-3abc-48ff-de1c-427bd28aeae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Pandas Data Preprocessing Techniques ---\n",
            "\n",
            "1. Categorical Encoding (One-Hot Encoding) using Pandas:\n",
            "Original unique values for 'experience_level': ['SE' 'EN' 'MI' 'EX']\n",
            "Original unique values for 'employment_type': ['CT' 'FL' 'PT' 'FT']\n",
            "\n",
            "DataFrame head after One-Hot Encoding (showing all columns including newly created dummy columns):\n",
            "    job_id              job_title  salary_usd salary_currency  \\\n",
            "0  AI00001  AI Research Scientist       90376             USD   \n",
            "1  AI00002   AI Software Engineer       61895             USD   \n",
            "2  AI00003          AI Specialist      152626             USD   \n",
            "3  AI00004           NLP Engineer       80215             USD   \n",
            "4  AI00005          AI Consultant       54624             EUR   \n",
            "\n",
            "  company_location company_size employee_residence  remote_ratio  \\\n",
            "0            China            M              China            50   \n",
            "1           Canada            M            Ireland           100   \n",
            "2      Switzerland            L        South Korea             0   \n",
            "3            India            M              India            50   \n",
            "4           France            S          Singapore           100   \n",
            "\n",
            "                                   required_skills education_required  ...  \\\n",
            "0         Tableau, PyTorch, Kubernetes, Linux, NLP           Bachelor  ...   \n",
            "1  Deep Learning, AWS, Mathematics, Python, Docker             Master  ...   \n",
            "2     Kubernetes, Deep Learning, Java, Hadoop, NLP          Associate  ...   \n",
            "3                        Scala, SQL, Linux, Python                PhD  ...   \n",
            "4                     MLOps, Java, Tableau, Python             Master  ...   \n",
            "\n",
            "   application_deadline job_description_length benefits_score  \\\n",
            "0            2024-11-07                   1076            5.9   \n",
            "1            2025-01-11                   1268            5.2   \n",
            "2            2025-04-07                   1974            9.4   \n",
            "3            2025-02-24                   1345            8.6   \n",
            "4            2025-06-23                   1989            6.6   \n",
            "\n",
            "        company_name  experience_level_EX  experience_level_MI  \\\n",
            "0    Smart Analytics                False                False   \n",
            "1       TechCorp Inc                False                False   \n",
            "2    Autonomous Tech                False                 True   \n",
            "3     Future Systems                False                False   \n",
            "4  Advanced Robotics                False                False   \n",
            "\n",
            "  experience_level_SE  employment_type_FL  employment_type_FT  \\\n",
            "0                True               False               False   \n",
            "1               False               False               False   \n",
            "2               False                True               False   \n",
            "3                True                True               False   \n",
            "4               False               False               False   \n",
            "\n",
            "   employment_type_PT  \n",
            "0               False  \n",
            "1               False  \n",
            "2               False  \n",
            "3               False  \n",
            "4                True  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "Explanation: `pd.get_dummies()` converts categorical columns into numerical (binary) columns. Each unique category value gets a new column, with 1 if the row belongs to that category and 0 otherwise. `drop_first=True` avoids multicollinearity by dropping the first dummy variable created for each original categorical column, which can vary based on alphabetical order of unique values.\n",
            "\n",
            "2. Feature Scaling (Min-Max Scaling) using Pandas:\n",
            "\n",
            "DataFrame head with scaled 'salary_usd' and 'years_experience' columns:\n",
            "   salary_usd  salary_usd_scaled  years_experience  years_experience_scaled\n",
            "0       90376           0.157831                 9                 0.473684\n",
            "1       61895           0.080136                 1                 0.052632\n",
            "2      152626           0.327646                 2                 0.105263\n",
            "3       80215           0.130112                 7                 0.368421\n",
            "4       54624           0.060301                 0                 0.000000\n",
            "\n",
            "Explanation: Min-Max Scaling transforms numerical features to a specific range (e.g., [0, 1]) by subtracting the minimum value and dividing by the range (max - min).\n",
            "\n",
            "--- NumPy Data Preprocessing Techniques ---\n",
            "\n",
            "1. Feature Scaling (Min-Max Scaling) using NumPy:\n",
            "Original 'salary_usd' (first 5 values): [ 90376  61895 152626  80215  54624]\n",
            "Original 'years_experience' (first 5 values): [9 1 2 7 0]\n",
            "Scaled 'salary_usd' (first 5 values):\n",
            "[0.15783085 0.08013618 0.32764556 0.13011217 0.06030127]\n",
            "Scaled 'years_experience' (first 5 values):\n",
            "[0.47368421 0.05263158 0.10526316 0.36842105 0.        ]\n",
            "\n",
            "Explanation: Individual columns are selected using array slicing (`[:, column_index]`). The array is explicitly converted to float (`.astype(np.float64)`) to ensure floating-point division. The Min-Max scaling formula is then applied element-wise using NumPy's vectorized operations. A copy of the array is made to demonstrate the scaled result without altering the original DataFrame's underlying array values if it were used elsewhere.\n",
            "\n",
            "2. Data Type Conversion (on numerical array) using Numpy:\n",
            "Original dtype of 'salary_usd' column (NumPy array): int64\n",
            "New dtype of 'salary_usd' column after conversion to float32: float32\n",
            "Syntax: array.astype(dtype) - Creates a new array with the same data converted to the specified data type.\n",
            "\n",
            "3. Simple Numerical Categorical Mapping (for 'remote_ratio') using NumPy:\n",
            "Original 'remote_ratio' (first 10 values): [ 50 100   0  50 100  50   0   0   0   0]\n",
            "Mapped 'remote_ratio' (first 10 values): [1 2 0 1 2 1 0 0 0 0]\n",
            "\n",
            "Explanation: `np.where(condition, x, y)` returns elements chosen from `x` or `y` depending on `condition`. Nested `np.where` is used to create a simple mapping for discrete numerical categories. This is a basic form of numerical encoding within NumPy, suitable for a limited number of known discrete values.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset for Pandas operations\n",
        "df_pandas = pd.read_csv('/content/ai_job_dataset.csv')\n",
        "\n",
        "print(\"--- Pandas Data Preprocessing Techniques ---\")\n",
        "\n",
        "# 1. Categorical Encoding: One-Hot Encoding\n",
        "# We'll apply One-Hot Encoding to 'experience_level' and 'employment_type'.\n",
        "# This converts categorical text data into numerical format, creating new binary columns for each category.\n",
        "print(\"\\n1. Categorical Encoding (One-Hot Encoding) using Pandas:\")\n",
        "print(\"Original unique values for 'experience_level':\", df_pandas['experience_level'].unique())\n",
        "print(\"Original unique values for 'employment_type':\", df_pandas['employment_type'].unique())\n",
        "\n",
        "df_pandas = pd.get_dummies(df_pandas, columns=['experience_level', 'employment_type'], drop_first=True)\n",
        "# drop_first=True prevents multicollinearity by dropping the first category of each feature.\n",
        "\n",
        "print(\"\\nDataFrame head after One-Hot Encoding (showing all columns including newly created dummy columns):\")\n",
        "# FIX: Instead of hardcoding dummy column names, print the head of the DataFrame\n",
        "# This will show all columns, including the new dummy columns that were actually created.\n",
        "print(df_pandas.head())\n",
        "print(\"\\nExplanation: `pd.get_dummies()` converts categorical columns into numerical (binary) columns. Each unique category value gets a new column, with 1 if the row belongs to that category and 0 otherwise. `drop_first=True` avoids multicollinearity by dropping the first dummy variable created for each original categorical column, which can vary based on alphabetical order of unique values.\")\n",
        "\n",
        "# 2. Feature Scaling: Min-Max Scaling\n",
        "# We'll apply Min-Max Scaling to 'salary_usd' and 'years_experience'.\n",
        "# Min-Max Scaling transforms features to a given range (e.g., 0 to 1).\n",
        "# Formula: X_scaled = (X - X_min) / (X_max - X_min)\n",
        "print(\"\\n2. Feature Scaling (Min-Max Scaling) using Pandas:\")\n",
        "numerical_cols_to_scale_pandas = ['salary_usd', 'years_experience']\n",
        "\n",
        "for col in numerical_cols_to_scale_pandas:\n",
        "    min_val = df_pandas[col].min()\n",
        "    max_val = df_pandas[col].max()\n",
        "    df_pandas[col + '_scaled'] = (df_pandas[col] - min_val) / (max_val - min_val)\n",
        "\n",
        "print(\"\\nDataFrame head with scaled 'salary_usd' and 'years_experience' columns:\")\n",
        "print(df_pandas[['salary_usd', 'salary_usd_scaled', 'years_experience', 'years_experience_scaled']].head())\n",
        "print(\"\\nExplanation: Min-Max Scaling transforms numerical features to a specific range (e.g., [0, 1]) by subtracting the minimum value and dividing by the range (max - min).\")\n",
        "\n",
        "\n",
        "df_numpy = pd.read_csv('ai_job_dataset.csv')\n",
        "numerical_cols_numpy = ['salary_usd', 'years_experience', 'remote_ratio']\n",
        "numpy_data = df_numpy[numerical_cols_numpy].values\n",
        "\n",
        "print(\"\\n--- NumPy Data Preprocessing Techniques ---\")\n",
        "\n",
        "# 1. Feature Scaling (Min-Max Scaling) using NumPy\n",
        "print(\"\\n1. Feature Scaling (Min-Max Scaling) using NumPy:\")\n",
        "\n",
        "# Get the indices for the columns we want to scale\n",
        "salary_usd_idx = numerical_cols_numpy.index('salary_usd')\n",
        "years_experience_idx = numerical_cols_numpy.index('years_experience')\n",
        "\n",
        "# Original data for comparison\n",
        "print(\"Original 'salary_usd' (first 5 values):\", df_numpy['salary_usd'].values[:5])\n",
        "print(\"Original 'years_experience' (first 5 values):\", df_numpy['years_experience'].values[:5])\n",
        "\n",
        "# Create a copy of numpy_data and ensure it's float type for scaling calculations\n",
        "numpy_data_scaled = numpy_data.copy().astype(np.float64) # Convert to float64 here\n",
        "\n",
        "\n",
        "# Apply Min-Max scaling\n",
        "min_salary = np.min(numpy_data_scaled[:, salary_usd_idx])\n",
        "max_salary = np.max(numpy_data_scaled[:, salary_usd_idx])\n",
        "numpy_data_scaled[:, salary_usd_idx] = (numpy_data_scaled[:, salary_usd_idx] - min_salary) / (max_salary - min_salary)\n",
        "\n",
        "min_years = np.min(numpy_data_scaled[:, years_experience_idx])\n",
        "max_years = np.max(numpy_data_scaled[:, years_experience_idx])\n",
        "numpy_data_scaled[:, years_experience_idx] = (numpy_data_scaled[:, years_experience_idx] - min_years) / (max_years - min_years)\n",
        "\n",
        "print(\"Scaled 'salary_usd' (first 5 values):\")\n",
        "print(numpy_data_scaled[:5, salary_usd_idx])\n",
        "print(\"Scaled 'years_experience' (first 5 values):\")\n",
        "print(numpy_data_scaled[:5, years_experience_idx])\n",
        "print(\"\\nExplanation: Individual columns are selected using array slicing (`[:, column_index]`). The array is explicitly converted to float (`.astype(np.float64)`) to ensure floating-point division. The Min-Max scaling formula is then applied element-wise using NumPy's vectorized operations. A copy of the array is made to demonstrate the scaled result without altering the original DataFrame's underlying array values if it were used elsewhere.\")\n",
        "\n",
        "# 2. Data Type Conversion (on a numerical array)\n",
        "\n",
        "print(\"\\n2. Data Type Conversion (on numerical array) using Numpy:\")\n",
        "salary_usd_original_np = df_numpy['salary_usd'].values\n",
        "print(\"Original dtype of 'salary_usd' column (NumPy array):\", salary_usd_original_np.dtype)\n",
        "\n",
        "# Convert to float32\n",
        "\n",
        "salary_usd_float32 = salary_usd_original_np.astype(np.float32)\n",
        "print(\"New dtype of 'salary_usd' column after conversion to float32:\", salary_usd_float32.dtype)\n",
        "print(\"Syntax: array.astype(dtype) - Creates a new array with the same data converted to the specified data type.\")\n",
        "\n",
        "\n",
        "#simple Numerical categorical Mapping (for 'remote_ratio')\n",
        "\n",
        "print(\"\\n3. Simple Numerical Categorical Mapping (for 'remote_ratio') using NumPy:\")\n",
        "remote_ratio_np = df_numpy['remote_ratio'].values # Get original for comparison\n",
        "print(\"Original 'remote_ratio' (first 10 values):\", remote_ratio_np[:10])\n",
        "\n",
        "# Using np.where for conditional mapping\n",
        "\n",
        "mapped_remote_ratios_np = np.where(remote_ratio_np == 0, 0,\n",
        "                                   np.where(remote_ratio_np == 50, 1, 2))\n",
        "\n",
        "print(\"Mapped 'remote_ratio' (first 10 values):\", mapped_remote_ratios_np[:10])\n",
        "print(\"\\nExplanation: `np.where(condition, x, y)` returns elements chosen from `x` or `y` depending on `condition`. Nested `np.where` is used to create a simple mapping for discrete numerical categories. This is a basic form of numerical encoding within NumPy, suitable for a limited number of known discrete values.\")"
      ]
    }
  ]
}